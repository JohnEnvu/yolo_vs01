1.  yolov8模型拆解

# c3
```bash
输入数据x

路径 A = Conv1(X)
conv是卷积
A_processed = BottleneckGroup(路径 A)
BottleneckGroup 内部就是多个 Output = f(Input) + Input 的累加
f(Input) - 残差块，也是一个矩阵，和卷积不一样，卷积得到一个点，残差块得到一个矩阵
输出 = （残差矩阵 + 输入矩阵）累加

路径 B = Conv2(X)

拼接结果 = Concat(路径 A_processed, 路径 B)
Concat 拼接两个矩阵，如将两个 10x10 的矩阵拼成一个 20x10 的矩阵

最终输出 = Conv3(拼接结果)
```
# 补充
1. 输入特征
图像 - 卷积 - 特征

2. 残差
输入信号x 加到 输出 f（x）上
y = f(x) + x
防止梯度消失，保证网络训练深度

3. bottleneck瓶颈

4. 深度
卷积层数
一个模型包含的卷积层、全连接层等运算层越多，我们就说这个模型越“深”。
学更抽象复杂的特征

5. 梯度消失
深层信息传递变难

# 项目结构
## 1. backbone - 骨干网络
1. 通过一系列处理得到图片特征
2. 处理过程 
浅层 - 提取边缘特征 - 边缘,线条,颜色斑点
深层 - 就是多层卷积+下采样之后的浓缩图片 - 图像特征
输出特征图,包含丰富的语义信息
3. backbone决定了模型的特征提取能力 - 是一切处理的前提
4. yolov8的backbone
引入残差连接防止梯度消失 - 在下采样时候不丢失特征信息
计算量小 - 快
### 残差连接为什么能防止梯度消失?
1. 梯度传递
简单来说各层的梯度通过乘法连接(传递)
总梯度 = 各个梯度连乘
存在一个问题:要每一层的梯度都很小,连乘之后的结果趋近于零
2. 残差连接解决了这个问题
y = f(x) + x
3. 梯度怎么算
残差公式 `y = F(x) + x`
我们要看 `y` 对 `x` 的梯度是多少，也就是 `dy / dx`：
- `dy / dx = (F(x) 的导数) + (x 的导数)`
- `F(x)` 的导数写成 `F'(x)`（这是卷积层的梯度，通常很小）。
- `x` 对自己的导数永远是 **1**（因为 x 变 1，x 就变 1）。
- 残差层梯度 = F'(x) + 1


5. 如果说**梯度**是改进的方向，**反向传播**是传递指令的渠道，那么**损失函数**就是那个**“打分的裁判”**。
6. 完整的链路
损失函数 - 反向传播 - 梯度 - 优化
#### 梯度概念
1. 一个向量 - 指函数上升最快的方向
2. 目的是梯度下降 - 向着梯度反方向走
#### 损失函数
> 概念
1. 损失函数是一个数学公式，用来计算模型的**预测值**与**真实值**之间的差距。
3. 预测越准，Loss 越接近 0。
预测越离谱，Loss 就越大。
**损失函数**就是那把阅卷的红笔，算出你丢了多少分。
4. 模型开始训练时没有参照标准,要根据这个loss值知道优化的方向

> 损失函数的种类
1. bce loss - 分类损失
看是否认错东西
2. ciou loss - 定位损失
框的准不准
看框的重叠度,中心距离,长宽比等
3. dfl loss - 分布损失
用在模糊的边界,对模糊边界定位更准
#### 反向传播概念
1. 一种高效计算网络中所有参数梯度的算法。
2. 前向传播 - 图片 - 第一层 - 第二层 - ... - 输出结果
3. 反向传播 - 误差结果 - 最后一层 - ... - 第一层
4. 算出错误在每一层的权重 - 梯度
5. 当前层梯度 = 局部梯度 * 上游梯度
又叫链式法则
在数学里，如果变量 y 依赖 u，而 u 又依赖 x，那么 y 对 x 的导数（变化率）就是两者导数的**乘积**。
- **公式**：`dy/dx = (dy/du) * (du/dx)`
- **在网络中的体现**：
    - 最终报错（Loss）对第一层权重的梯度，等于中间经过的所有层导数的**连乘**。
> 梯度是相对于每个变量的
`f = q * z`
就要算q和z的梯度
> 局部梯度
当前层运算公式的求导结果
> 上游梯度
反向传播过来的
> 得到梯度之后要做什么
根据梯度把参数往反方向拨一点
> 为什么要引入残差
方向传播时信号会衰减
#### 完整反向传播计算过程
```bash
### 19.1 场景设定
我们有一个最简单的神经元：`y = w * x + b`
- **输入**：`x = 3`
- **初始权重**：`w = 2`
- **偏置**：`b = -1`
- **目标值**：我们希望输出结果是 `10`
- **损失函数**：`Loss = (y - 目标值)^2`

### 19.2 第一阶段：前向传播（算结果）
1. **乘法层**：`u = w * x = 2 * 3 = 6`
2. **加法层**：`y = u + b = 6 + (-1) = 5`
3. **Loss 层**：`Loss = (5 - 10)^2 = 25`
   - **结论**：模型现在算出来的结果是 5，离目标 10 还差很远，报错量（Loss）是 25。

### 19.3 第二阶段：反向传播（分锅算梯度）
#### 步骤 1：从 Loss 层开始（起点）
我们要看 `y` 变一点点，`Loss` 会变多少。
- **公式**：`Loss = (y - 10)^2` 的导数是 `2 * (y - 10)`
- **计算**：`2 * (5 - 10) = -10`
- **结果**：**上游梯度 = -10**。它告诉前面：“结果小了，得增加”。
#### 步骤 2：回到加法层 (`y = u + b`)
- **局部梯度**：因为是加法，`y` 对 `u` 的导数是 `1`，对 `b` 的导数也是 `1`。
- **算 u 的梯度**：`上游(-10) * 局部(1) = -10`
- **算 b 的梯度**：`上游(-10) * 局部(1) = -10`
- **结果**：`u` 和 `b` 各自领到了 `-10` 的梯度。
#### 步骤 3：回到乘法层 (`u = w * x`)
- **局部梯度**：
    - `u` 对 `w` 的导数是 `x`（即 3）。
    - `u` 对 `x` 的导数是 `w`（即 2）。
- **上游梯度**：来自步骤 2 算出的 `u` 的梯度，即 `-10`。
- **算 w 的梯度**：`上游(-10) * 局部(x=3) = -30`
- **算 x 的梯度**：`上游(-10) * 局部(w=2) = -20`
### 19.4 最终结果：谁该负责？
经过这一轮反向连乘，我们得到了每个参数的梯度：
- **w 的梯度 = -30**
- **b 的梯度 = -10**
### 19.5 终章：怎么修改？（优化）
模型会根据梯度更新参数（假设学习率是 0.01）：
- **新 w** = `旧 w - (0.01 * 梯度) = 2 - (0.01 * -30) = 2.3`
- **新 b** = `旧 b - (0.01 * 梯度) = -1 - (0.01 * -10) = -0.9`

**验证**：用新参数再算一遍：`2.3 * 3 + (-0.9) = 6.9 - 0.9 = 6.0`。
看！结果从 `5` 变成了 `6`，离目标 `10` 更近了！这就是反向传播和梯度带给模型的“进化”。
```
1. 这里面很重要的一个点就是函数的拆分

### - 下采样
> 压缩图片, 提取特征
> 输出尺寸 = (输入尺寸 - 卷积核尺寸) / 步长 + 1
> (640 - 3) / 2 + 1 = 319.5 -> 取整约 320
    图像变小，特征浓缩 - 640x640 变成320x320
    减少计算量，更快
    让卷积核能看到更多的信息
    用一个2步长卷积，步长就是扫描时候移动的距离 - Stride=2 Conv
    输出尺寸 = (输入尺寸 - 卷积核尺寸) / 步长 + 1
    (640 - 3) / 2 + 1 = 319.5 -> 取整约 320
### - 卷积如何把图片变小的
> 卷积核扫描是移动距离,比如步长是2,卷积核大小是1,那就是1 - 3 - 5 
> 第三行 1 - 3 - 5
> 横纵都是2的移动步长
```bash
普通卷积（Stride=1）是挨个像素扫描，而 **Stride=2** 则是“跳着走”。
- **过程**：
    1. 卷积核在起始位置计算一次。
    2. 卷积核向右移动 **2 个像素**（跳过中间那个，从1到3，2忽略），再计算一次。
    3. 这一行扫完后，向下移动 **2 个像素**，开始扫下一行。
- **结果**：因为你跳过了一半的像素，所以输出的特征图在横向和纵向上都只有原来的一半大。
```
### - 卷积核内部的计算过程
> 卷积核只输出一个点，特征点，对图片有压缩效果
```bash
1. 卷积之后输出的是特征图，不是简单的缩放，是一堆杂乱的色块
2. 无论卷积核多大，扫描一次只出一个点
3. 
**准备阶段**：
   - 卷积核里有 4 个预设好的数字（权重），比如：`[w1, w2, w3, w4]`。
   - 图片被覆盖的区域也有 4 个像素值，比如：`[p1, p2, p3, p4]`。
**计算阶段（乘法）**：
   - 对应位置相乘：`a = w1*p1, b = w2*p2, c = w3*p3, d = w4*p4`。
**融合阶段（加法）**：
   - 把乘积全加起来：`输出值 = a + b + c + d`。
   - 这一步就是最关键的“降维”——无论你之前覆盖了多少个点，最后都融合成了一个总和。
```


## 2. neck - 颈部网络
    特征融合 - 拼接backbone出来的不同深度特征 - fpn+pan结构 - 融合特征
- fpn+pan结构
    fpn - 从上往下 - 深层语义信息传给浅层
    语义信息 - 物体是什么，特征
    pan - 从下往上 - 浅层位置信息传给深层
    位置信息 - 物体边缘，轮廓
    解决深层只知道是什么，但是位置模糊，和浅层不知道是什么，但是位置精准的问题

## 3. head - 检测头
    最终预测 - decoupled head（解耦头） -  将分类回归分开，
- decoupled head（解耦头）
    之前版本分类和回归是在一个卷积层的，现在分开
    分类关注物体特征，回归关注物体轮廓
    分开模型收敛更快，精度更高


# 2. 文件结构
模型
神经网络组件
engine - 训练，验证
data - 数据预处理

# 模型结构
1. 
https://blog.csdn.net/AngelCryToo/article/details/157068878?ops_request_misc=&request_id=&biz_id=102&utm_term=yolov8&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-157068878.142^v102^pc_search_result_base9&spm=1018.2226.3001.4187
2. 
┌─────────────────────────────────────────┐
│              Input (640×640)             │
├─────────────────────────────────────────┤
│                 Backbone                 │
│        CSPDarknet53 + SPPF增强版         │
├─────────────────────────────────────────┤
│                   Neck                   │
│        PAN-FPN (Path Aggregation)       │
├─────────────────────────────────────────┤
│                   Head                   │
│    Decoupled Head + Anchor-Free设计      │
└─────────────────────────────────────────┘
3. 结构精读
# 骨干网络
```py
class CSPDarknet53_Enhanced:
    """
    改进的CSPDarknet骨干网络
    """
    def __init__(self):
        # 1. 使用C2f模块替代C3模块
        # 2. 引入SPPF（Spatial Pyramid Pooling Fast）
        # 3. 改进的梯度流设计
        # 4. 更高效的跨阶段连接
        
    def forward(self, x):
        # 5层特征提取
        return [p3, p4, p5]  # 多尺度特征
```
## c3
1. 使用 3 个卷积层和一组残差连接（Bottleneck）来提取特征
### 残差
1. 正常的神经网络是 A -> B -> C 这样一层层传下去。残差连接则是：在传给下一层的同时，把原始输入直接“跳级”传给后面的层，最后加在一起。
即使中间的层f(Input)什么都没学会，至少原始信息Input能传下去，保证了深层网络的稳定性。
Output = f(Input) + Input
### 3 个卷积层 + 残差连接
1. 叫c3是因为有3个卷积层conv
输入数据x

路径 A = Conv1(X)
conv是卷积
A_processed = BottleneckGroup(路径 A)
注：这里的 BottleneckGroup 内部就是多个 Output = f(Input) + Input 的累加
f(Input) - 残差块，也是一个矩阵，和卷积不一样，卷积得到一个点，残差块得到一个矩阵
输出 = 残差矩阵 + 输入矩阵

路径 B = Conv2(X)

拼接结果 = Concat(路径 A_processed, 路径 B)
注：Concat 是物理上的拼接，比如两个 10x10 的矩阵拼成一个 20x10 的矩阵

最终输出 = Conv3(拼接结果)

### 卷积conv
输入矩阵3x3
1  2  0
3  1  1
0  2  2

卷积核2x2
1  0
0  1

假设步长为1
输入局部:    卷积核:
[1  2]  与  [1  0]
[3  1]      [0  1]
(对应位置相乘，再相加)
结果1 = (1 * 1) + (2 * 0) + (3 * 0) + (1 * 1)
结果1 = 1 + 0 + 0 + 1 = 2

向右移动一格
输入局部:    卷积核:
[2  0]  与  [1  0]
[1  1]      [0  1]
结果2 = (2 * 1) + (0 * 0) + (1 * 0) + (1 * 1)
结果2 = 2 + 0 + 0 + 1 = 3
。。。

最终输出
2  3
5  3
### 卷积核种类
找出图片所有垂直线
-1  0  1
-1  0  1
-1  0  1
找出图片所有水平线
-1 -1 -1
 0  0  0
 1  1  1
让图片模糊
1/9  1/9  1/9
1/9  1/9  1/9
1/9  1/9  1/9
让图片锐化
 0 -1  0
-1  5 -1
 0 -1  0

1. 深度学习中的卷积核数字是随机生成的，是不断学习和调整的
比如：如果它要识别“车轮”，它会自动学出一个能提取“圆弧”特征的卷积核。

## c2f
1. 通过更多的 分支 和 跳跃连接 ，让模型在保持轻量化的同时，获得了更丰富的 梯度流 （信息传递路径）。
2. 效果 ：比 C3 提取特征的能力更强，且推理速度更快。
### 具体过程
输入x

基础特征 = Conv1(X)
X1, X2 = Split(基础特征)
注：Split 是把特征图按通道数一分为二。X1 就像是“存起来备用”的原始信息，X2 准备去参加级联计算。

级联计算 - 每级连起来
G1 = Bottleneck1(X2)
G2 = Bottleneck2(G1)
G3 = Bottleneck3(G2)

汇总结果 = Concat(X1, X2, G1, G2, G3)

最终输出 = Conv2(汇总结果)

## SPPF (Spatial Pyramid Pooling Fast)
- SPP (空间金字塔池化) ：最初是为了解决输入图像尺寸不固定的问题，通过不同尺度的池化（如 5x5, 9x9, 13x13）来获取不同范围的感受野，捕捉大大小小的物体信息。
- SPPF (快速版 SPP) ：
  - 改进点 ：它不再并行运行多个大尺寸池化，而是改用 串行 的小尺寸池化（例如连续做三次 5x5 池化）。
  - 效果 ：数学上等价于原来的大尺寸池化，但计算量大大减少，执行速度显著提升。
1. spp卷积核大小是固定的，要么只能识别大物体，要么只能识别小物体
2. sppf就是步长为1，连续池化3次，
### 池化
1. 在一个小矩阵（如 2x2）内，只取一个代表值，也有步长
注意，只有步长大于1图片才会缩小，步长2，就会缩小一半
步长1图片的分辨率是不变的

这里涉及到一个概念，卷积扫描之后输出的图像分辨率公式
**输出尺寸 = (输入尺寸 + 2 * 填充 - 卷积核尺寸) / 步长 + 1**
通常向下取整
填充 (Padding) ：为了保护边缘信息，在图像外面补的“ 0 ”的圈数。

2. 池化类型
- 最大池化 (Max Pooling) ：只取窗口里的最大值。代表“这里最显著的特征是什么”。
- 平均池化 (Average Pooling) ：取窗口里的平均值。代表“这里的平均背景是什么”。
3. 目的
- 减小数据量 ：图像变小了，计算就快了。
- 平移不变性 ：就算物体稍微移动了一点，池化后的结果依然差不多，增强了模型的鲁棒性。
4. 池化和卷积核不一样，固定的，二者的目的不一样
卷积是学习特征
池化是降维，减少计算量，强化特征，因为会把卷积扫描后会把区域内的值换成特征值，比如最大值或者平均值等
池化之后视野会变广
5. 视野，深度学习中专业术语，感受野
一个像素点能“看”到原图中多大的范围
普通的池化（跳着走） ：就像你拿着一个放大镜看报纸，看一眼（2x2），然后 跳过去 看下一块。虽然你每次看到的范围有限，但因为你跳着走，很快就能把整张报纸看完（图片变小了），代价是细节变模糊了。

SPPF 的池化（蹭着走） ：就像你拿着放大镜，在报纸上 一点一点挪动（步长为 1） 。
第一遍挪完：你虽然看的是局部，但你把所有细节都保留了。
叠加第二遍：因为你是在第一遍的基础上再看，这一层的一个点，其实包含了上一层周围好几个点的信息。
结果 ：最后那个点虽然还是一个点，但它“背后的记忆”里已经包含了原图很大一片区域的信息。

SPPF 核心是连续叠加 3 个 5x5 的池化层（步长 Stride = 1）。
第 1 层池化后 ：
   - 输出的 1 个像素点，能看到输入图中 5x5 的区域。
   - 视野 = 5 。
第 2 层池化后 （在第 1 层的结果上再做 5x5）：
   - 这一层的 1 个像素点，看到了前一层 5x5 的像素。
   - 因为前一层每个像素已经自带 5x5 视野了，叠加后：
   - 视野 = 5 + (5 - 1) = 9 。（即 9x9 的区域）
第 3 层池化后 （再叠加一次）：
   - 视野 = 9 + (5 - 1) = 13 。（即 13x13 的区域）

6. 池化的具体流程，图像化
5x5的卷积核，在图像的第一个点，左上角，卷积之后将25个点的视野浓缩成最左上角的一个点，就是1x1位置这个点
然后步长为1，右移一格
同一，1x2这个位置的点浓缩了2-6，l1-5（l是竖着数）这25个点
根据例子，



## 4. 梯度流设计 (Gradient Flow)
- 定义 ：在神经网络训练（反向传播）时，误差信号（梯度）从最后一层传回第一层的路径。
- 改进意义 ：
  - 如果梯度流设计不好，深层网络容易出现“梯度消失”（信号传丢了）或“梯度爆炸”。
  - C2f 等模块的设计目的就是增加路径的复杂度和密度，让每一层都能接收到更清晰的指令，从而学得更快、更准。

## 5. 跨阶段连接 (Cross-stage connection)
- 定义 ：这是 CSPNet (Cross Stage Partial Network) 的核心思想。
- 原理 ：将基础层的特征图分成两部分：
  1. 一部分经过复杂的瓶颈层（Bottleneck）进行计算。
  2. 另一部分直接“跨过”这些计算，最后再与第一部分合并。
- 效果 ：
  - 减少冗余 ：避免了重复学习相同的特征信息。
  - 降低计算量 ：相当于只让一部分数据去干重活，效率更高。

# 名词汇总
## 骨干网络
### 1. 卷积核
一个矩阵
深度学习中卷积核会根据学习程度自动改变矩阵内容

提取特征，卷积核中心点输出的是特征，如眼睛等要识别的目标
### 2. 卷积conv
1. 
两个矩阵对应位置上的数相乘再相加
得到一个点
这个其实不是卷积的定义，是点乘的定义，或者说是卷积核内部计算过程的名字
2. 
官方定义 ：一种数学运算，通过一个函数（卷积核）在另一个函数（输入）上滑动来产生第三个函数（输出特征图）。
卷积就是用卷积核扫描输入矩阵的全过程
3. 
卷积层
官方定义 ：神经网络中的一个功能层，包含权重（卷积核参数）和偏置，通过执行卷积操作来提取输入数据的空间特征。
你的理解 ：它是一个 结构单位 ，非常准确。它就像一个“工厂车间”，卷积核是里面的“机器”，卷积是“生产工艺”。
### 3. 残差
1. 
对矩阵的缩放，用于特征提取
如让整个矩阵x0.1

残差矩阵可以叫残差块，然后两个矩阵对位相乘（和矩阵乘法不一样的，忘记矩阵乘法怎么算了）
矩阵对位相乘的学名叫 - 哈达马积累
和点乘不一样，点乘是对位相乘再求和，就是卷积，输出的是一个点，对位相乘输出还是矩阵
就叫对位相乘好了

矩阵乘法是叉乘，左矩阵的行，乘右矩阵的列，然后求和
这里是矩阵的特征映射，不是很明白怎么个映射了
卷积和矩阵的乘法是不一样的，卷积更像是点乘之后求和

2. 
残差到底在做什么
输入x
原件保留，然后复印一份x‘，x = x’
将复印的x’拿去给卷积层，输出f（x‘）

卷积层的计算过程
为了保证输入输出矩阵大小一样，要填充padding
假设卷积核是2x2，那就要在输入外面填充一层padding，从2x2变成3x3
补padding是从左、上补，或者在右、下补
原始 X:      填充后的 X (3x3):
1 2          1 2 0
3 4    -->   3 4 0
             0 0 0  <-- 补的 0
（每次卷积都会让外围减少若干圈，主要看卷积核的内边距，3x3就是一层，5x5就是两层）

空间尺寸缩小和降维之前的区别
空间尺寸缩小 - 如3x3变成2x2
降维 - 通道数减少

然后残差连接
output = x + f（x‘）

### 4. 物理拼接concat
将两个矩阵拼在一起，左右拼接
两个2x2矩阵，拼接后变成4x2矩阵
### 5. spp sppf
spp池化矩阵大小固定，只能识别大物体或者小物体

sppf
连续做3次池化
初始感受野是1
第一次池化之后
用的5x5的卷积核 - 感受野变成5，一个像素点能看到5x5的区域

第二次池化
去掉重叠部分，向外拓展的感受野是左边2，右边2，感受野是9
也就是第二次池化输出的那个点，能看到9x9的区域
因为池化是将整个区域的信息都压缩到一个点
第一次吃池化之后的输出矩阵每个点代表了5x5的区域，然后这时池化核扫描的5x5区域内的点，中间重叠部分都抵消掉了，只有最边缘的一圈，，看着是1视野，但是实际上代表的视野是5x5，也就是整个池化核外围还有两层的视野，实际上整个池化核的感受视野是9x9
就是这5x5的池化核能看到9x9的区域
然后池化之后输出一个点，这个点代表了9x9的区域

第三次池化
一个点代表9x9的区域，挑一个边缘的点作为中心点去看，可以看到向外拓展了4层，也就是实际5x5的区域，能看到5+4+4 = 13个点的信息（这里要注意，是一个边界的点拓展4层，转一圈下来，整个区域的面积是左和右，上和下都要加起来，不能只加一边的）

### 6. 池化
矩阵扫描，根据池化的类型在矩阵中取一个代表值，如最大值，平均值

池化的矩阵叫池化核（卷积的扫描矩阵叫卷积核）

池化矩阵的值是不变的，和卷积核不同，卷积核会随着学习不断变化

池化目的是减小图片尺寸，根据步长调节
扩大视野范围，让每个像素点代表的信息更多
池化之后中心点输出的是矩阵内图片的浓缩信息

感受野
一个像素点能看到多大的原图范围

### 7. 卷积扫描之后输出的图片尺寸
**输出尺寸 = (输入尺寸 + 2 * 填充 - 卷积核尺寸) / 步长 + 1**

填充
就是padding，外边距
假设输入图片4x4，卷积核大小3x3，步长为1
扫描时扫描4次，中间2x2的部分被扫描4次，但是边缘的一圈只被扫描了1次

扫描频率不一样带来的影响叫 - 边缘偏差
导致特征提取不充分
扫描次数少的特征，会随着网络层数加深被中心高频扫描部分的特征覆盖掉
Padding 的作用 ：通过补 0，强制让边缘像素也参与多次计算，从而告诉神经网络：“边缘的信息和中心的信息一样值得被关注。”

步长
步长 是为了减少计算量或压缩尺寸（步长 > 1 会让重叠变少）。
步长与梯度
步长（学习率）：你迈出的这一步有多大。迈太大会跨过谷底，迈太小下山太慢。

### 9. 卷积核扫描
开始扫描的位置
假设有一个3x3的矩阵
扫描的时候卷积核是左上角对齐第一个像素
但是卷积核输出的位置是中心点
这里可以得出卷积扫描之后输出图像会小一圈
想要保证输出图像的尺寸不变，就要设置好padding

像是2x2，4x4这种偶数卷积核一般是左上角优先（没有明确的中心点）
一般卷积核都会选用奇数卷积核

卷积核扫描之后输出图像尺寸
输出尺寸 = (输入尺寸 + 2 * padding - 卷积核尺寸) / 步长 + 1

### 10. 梯度流
1. 
梯度
反向传播时候的修正信号
一般是向着梯度反方向修改

假设我们的损失函数（衡量模型错得有多离谱）是： Loss = w^2 我们的目标是找到让 Loss 最小的 w 值（显而易见， w = 0 时最小）。
第一步：当前状态
假设现在模型随机初始化了一个权重 w = 3 。
此时的误差 Loss = 3^2 = 9 。
第二步：计算梯度
梯度就是函数对参数的导数。
对于 w^2 ，它的导数是 2w 。
当 w = 3 时， 梯度 = 2 * 3 = 6 。

- 梯度的意义 ：它告诉你，如果 w 增加，误差会以 6 的斜率飞速上升。 第三步：反方向更新参数
我们要减小误差，所以要往梯度的 反方向 走。
设定学习率（步长） eta = 0.1 。
更新公式： w_new = w_old - 学习率 * 梯度
w_new = 3 - 0.1 * 6 = 3 - 0.6 = 2.4 第四步：检查结果
新的权重 w = 2.4 ，此时新的误差 Loss = 2.4^2 = 5.76 。 你看，误差从 9 降到了 5.76！ 模型变得更聪明了。

使用背景
问题 ：如果网络太深，梯度在往回传的时候，经过层层复杂的乘法计算，可能会变得越来越小（梯度消失），导致前面的层学不到东西。
梯度流设计 ：就是通过改变网络的拓扑结构，给梯度提供多条、更短的回传路径。
2. 
yolov8中的梯度流处理
c2f - 两个卷积处理分支的意思（对应c3就是3个卷积层，分支a，分支b，ab拼接）
c2f的运行逻辑
```bash
输入数据 X

1. 第一步：初步降维 (Conv1)
- Y = Conv1(X)
- 注：通常是一个 1x1 卷积核，用于调整通道数。
虽然是1x1的卷积核，但是高度（通道数是核输入一样的）

这里的步骤主要是讲输入图片的通道数根据不同的卷积核输出不同的特征值
1x1这个点的所有通道，输入到卷积核中，被压缩的只剩下一个通道，从1x1x128变成1x1x1
这样重复操作64次，重新筛选出64通道的特征值（根据卷积次数来决定通道数，即要保留的特征数）

每个卷积核都有不同的权重(就是一个卷积核的128个通道的权重都不一样，每个卷积核之间也不一样，有点像是残差，不过残差没有求和的过程)，来提取不同的特征

2. 第二步：分流 (Split)
- Y_left, Y_right = Split(Y)
输入的y是第一步输出的64通道的图片，就是一个由64张含不同特征解读的二维矩阵叠在一起形成的一个立方体
这就是计算机视觉中“张量”的样子，坐标从二维变成三维，这个立方体的名字就叫张量
通道又叫维度，这些其实就是多维数组，多维数组统称张量

卷积核一般都是三维的，平时数的只是平面尺寸，卷积核的厚度必须等于通道数
卷积核扫描之后得到一个二维平面，所以要用很多不同权重的卷积核控制输出的通道数

Split(Y)分流
保留一半通道不处理，将另一半通道拿去提取高阶特征
为了解决梯度消失，梯度是错误信号，从后往前传，过程中有消失的风险（乘法中）
一半不做处理就不用担心梯度会消失
分流效果
最后输出既有原始部分的低阶特征，也有处理之后的高阶特征（详细的处理就是卷积两次，对位相加一次，残差链处理）

分流有什么依据吗？
没有，直接从中间切开
在步骤一的1x1卷积之后就会把简单的边缘特征放到前半部分，把复杂的纹理信息放在后半部分

3. 第三步：残差链处理 (Bottlenecks)
- B1 = Bottleneck_1()
- B2 = Bottleneck_2(B1)
- ...
- Bn = Bottleneck_n(B_{n-1})
- 注：这里是一串残差块，每个块的输出都会被 实时记录 下来。
Bottlenecks
每个bottlenecks都有两个卷积和一个对位相加
卷积a
1x1卷积调整通道
（确定概念之后，卷积就是代表用卷积核扫描整个图像的完整过程）
卷积b 
在卷积a之后，再用 3x3 卷积核扫一遍，提取空间特征。
提取空间特征
将input和卷积b之后的结果对位相加
Output = Input + f(Input)

残差的作用
没有残差在深层向浅层传递的时候，梯度就会消失

怎么个消失法
由浅到深，一直在卷积，得到特征
反向传播，由深到浅
产生梯度的过程：
最深处得到的预测结果和真实结果对比，算出一个误差，这个误差就是梯度
梯度一层层回传，告诉每一层的卷积核自己权重不对

反向传播具体在做什么（不是简单的说反向传播，而是要知道这个动作是在做什么）

残差卷积和普通卷积之间的差别
普通的卷积是f（x）= output
卷积会磨损特征,卷积是一个提取特征的过程，也就是会有被舍过滤掉的信息，要是卷积核没学好，重要的像素信息就会被舍弃掉，只留下抽象信息

残差卷积是output = f（x）+ input
因为有input在，原输入的信息一直保留着，不用担心被卷积改掉重要特征
这只是一个纠错手段，那要是学习错了，要怎么改回来？怎么用input？
·················
我是知道这样能找到，程序知道吗？网络在学习的时候知道吗？网络在什么时候会回去找原始特征？

这是一个直击灵魂的问题。网络当然没有人类那样的“主观意识”去主动找原始特征，它是通过 数学机制 和 优胜劣汰 被动实现的。

我们可以从两个阶段来看它如何“知道”：

### 1. 学习阶段（改错）：梯度是它的“记忆力”
正如你提到的，加法是可逆的。在 反向传播 时，数学上有一个铁律： 和的导数等于导数的和 。

- 公式： Output = Input + f(Input)
- 求导（找梯度）： d(Output) / d(Input) = 1 + d(f(Input)) / d(Input)
关键就在这个 “1” 上：

- 无论 f(Input) 这一路怎么磨损特征、怎么丢信号，那个 “1” 永远存在。
- 它就像是网络的一种**“数学直觉”**：当末端的 Loss（误差）传回来时，网络通过这个 “1” 瞬间意识 到：“哦！原始的 Input 信息原来一直藏在这个 Output 后面，我可以绕过复杂的 f，直接去修改或者利用它。”
### 2. 推理阶段（干活）：卷积核是它的“过滤器”
到了实际预测时，网络确实已经把两个东西加在一起变成 1.1 了。它在什么时候会“回去找”？

答案是：它不需要回去找，因为它在扫描 1.1 的时候，就已经同时看到了两者。

- 卷积核的视角 ：下一层的卷积核有 9 个权重（如果是 3x3）。
  - 训练结束后，某些权重可能会变得对“大轮廓”很敏感。
  - 当它扫过 1.1 时，大轮廓的信号主要来自那个 1.0 （原始特征）。
  - 于是，这组权重就会自动从 1.1 中“提取”出属于原始特征的那部分贡献。
### 3. 网络什么时候会“偏爱”原始特征？
网络在以下两种情况会表现出明显的“回去找原始特征”的倾向：

1. 当卷积层学坏了（退化） ：
   如果 f(Input) 的卷积核乱学，导致误差变大，网络在改错时会发现：“既然你卷积层学得这么烂，我干脆把你的权重全部降到接近 0，我只用那个 1.0 （原始特征）算了！”
   这就是著名的**“恒等映射”**——网络发现不加干预的效果比乱干预更好，于是它就只用原始特征。
2. 当需要定位细节时 ：
   在 YOLO 这种检测任务中，最后预测物体位置时，需要非常精准的边缘。卷积层提取的特征往往太“抽象”了，边缘都模糊了。此时，网络会通过训练，让权重更多地去关注 Output 中保留的原始像素信息，以找回精确的坐标。
### 总结
- 程序知道吗？ 知道，写在反向传播的数学公式（求导）里。
- 网络知道吗？ 知道，体现在它不断尝试减少误差的过程中，发现利用原始特征能让误差更小。
- 什么时候找？ 改错时通过梯度“高速公路”找；干活时通过精心设计的卷积核权重“复合提取”找。
我已经将“梯度 1 的物理保障”和“卷积核复合提取逻辑”记录在 memory.md 中。

我们要接着看最后一步 全量大拼接 (Dense Concat) 吗？看看这些被保留、被加工、被筛选的特征是如何在大终点集合的。
·················

这也只是说了前因后果，具体是怎么做的还不知道
残差连接是对位相加
f（x）+ input 就叫残差
对位相加有个条件，就是两个张量的形状要一样（叫矩阵也行，只是维度不同）

特征是怎么读的？
都说卷积是提取特征，每一层之间的特征是怎么传递的？
特征在数学上是什么？
根据公式Output = Input + f(Input) - 这是一个矩阵
这个残差网络中下一层的输入是上一层的output
根据公式卷积核会识别出哪一部分是原始信息，哪一部分是加工信息
然后根据需求选择取用两个信息的权重，再进行卷积

修改权重就是修改卷积核，卷积本身就带有权重计算
- 如果权重长得像一个“横杠”，它扫过图像时就能提取出横边。
- 如果权重长得像一个“圆圈”，它就能提取出圆形特征。
·················
### 3. 为什么说权重决定了“取舍”？
回到残差连接 Output = Input + f(Input) ：

- 下一层卷积核扫过这个混合信号时，如果它的权重矩阵设计得能与 Input 产生共鸣（数学上的互相关运算结果大），那它就倾向于提取原始信息。
- 反之，如果它的权重能与 f(Input) 产生共鸣，它就提取加工信息。
- 谁定这些权重？ 梯度定。梯度会引导权重进化成最能减少误差的样子。
### 总结
- 卷积核 ：是执行任务的“工具”。
- 权重 ：是工具上的“旋钮”。
- 学习 ：就是根据任务反馈，不断拧这些“旋钮”，直到工具变得无比好用。
·················

4. 第四步：全量大拼接 (Dense Concat)
- 拼接结果 = Concat(Y_left, Y_right, B1, B2, ..., Bn)
- 核心改进 ：C3 只拼接两个分支的终点，而 C2f 把 初始的分支 + 所有残差块的中间结果 全部拼在了一起。
- 注：这就像把所有楼层的监控画面全部实时显示在一个大屏幕上。

5. 第五步：融合输出 (Conv2)
- 最终输出 = Conv2(拼接结果)
- 注：用最后一个卷积层将所有拼接的信息进行融合。
```
### 11. 通道数
卷积核大小是1x1，但是通道数会自动匹配输入数据的通道数
假设输入的通道数是128，那卷积核就是一根1x1x128的细长棒子

神经网络中的通道数，就是图片的深度，随着图片变深，通道数会代表着某种特征
比如通道1代表横向边缘，通道2代表圆形轮廓...
128个通道就是这一点上，有128种不同的特征

通道数和特征值
提到的“128 种特征”，本质上是模型在 同一个像素点 上，从 128 个不同的角度（维度）去描述这个点属于什么。
